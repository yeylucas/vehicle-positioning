{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b980fb99",
   "metadata": {},
   "source": [
    "## Import Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d18ad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import scipy.io \n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import time\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True' \n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8606c205",
   "metadata": {},
   "source": [
    "## Dataset Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2dca00",
   "metadata": {},
   "source": [
    "### Read in the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58c7763d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl_origin = torch.load('Dataset/train_dl.pt', weights_only=False)\n",
    "valid_dl_origin = torch.load('Dataset/valid_dl.pt', weights_only=False)\n",
    "\n",
    "train_CSI = train_dl_origin.dataset[:][0]\n",
    "train_label = train_dl_origin.dataset[:][1][:,0:2]\n",
    "\n",
    "valid_CSI = valid_dl_origin.dataset[:][0]\n",
    "valid_label = valid_dl_origin.dataset[:][1][:,0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7566af9",
   "metadata": {},
   "source": [
    "### CSI Processing: Take Modulus of complex matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f91b91df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_CSI_modulus = torch.abs(train_CSI)\n",
    "valid_CSI_modulus = torch.abs(valid_CSI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1257ed76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15000, 1, 4, 1632])\n",
      "torch.Size([5000, 1, 4, 1632])\n",
      "torch.Size([15000, 2])\n"
     ]
    }
   ],
   "source": [
    "print(train_CSI_modulus.shape)\n",
    "print(valid_CSI_modulus.shape)\n",
    "print(train_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db9fa7c",
   "metadata": {},
   "source": [
    "### CSI Processing: Normalize to [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normalize",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15000, 1, 4, 1632])\n",
      "torch.Size([5000, 1, 4, 1632])\n"
     ]
    }
   ],
   "source": [
    "# *Avoiding data leakage\n",
    "train_min = train_CSI_modulus.min()\n",
    "train_max = train_CSI_modulus.max()\n",
    "\n",
    "train_CSI_norm = (train_CSI_modulus - train_min) / (train_max - train_min)\n",
    "valid_CSI_norm = (valid_CSI_modulus - train_min) / (train_max - train_min)\n",
    "\n",
    "print(train_CSI_norm.shape)\n",
    "print(valid_CSI_norm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepare_data",
   "metadata": {},
   "source": [
    "### Preparing Data for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flatten",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening data to be 2D, 1d vector\n",
    "train_CSI_ML = train_CSI_norm.reshape(train_CSI_norm.shape[0], -1)\n",
    "valid_CSI_ML = valid_CSI_norm.reshape(valid_CSI_norm.shape[0], -1)\n",
    "\n",
    "print(train_CSI_ML.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ml_section",
   "metadata": {},
   "source": [
    "## Machine Learning: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linreg",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE:  22.084903717041016\n",
      "Valid MSE:  22.998790740966797\n",
      "Train RMSE:  4.6994578109651135\n",
      "Valid RMSE:  4.795705447686169\n",
      "Training time taken: 28.73s\n",
      "Validation time taken: 0.04s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "linreg = LinearRegression()\n",
    "\n",
    "start_time = time.time()\n",
    "linreg.fit(train_CSI_ML, train_label)\n",
    "train_time = time.time() - start_time\n",
    "\n",
    "# Evaluating on training set\n",
    "train_pred = linreg.predict(train_CSI_ML)\n",
    "train_mse = mean_squared_error(train_label, train_pred)\n",
    "train_rmse = math.sqrt(train_mse)\n",
    "\n",
    "# Evaluating on validation set\n",
    "start_valid_time = time.time()\n",
    "valid_pred = linreg.predict(valid_CSI_ML)\n",
    "valid_time = time.time() - start_valid_time\n",
    "\n",
    "valid_mse = mean_squared_error(valid_label, valid_pred)\n",
    "valid_rmse = math.sqrt(valid_mse)\n",
    "\n",
    "print('Training MSE: ', train_mse)\n",
    "print('Valid MSE: ', valid_mse)\n",
    "print('Train RMSE: ', train_rmse)\n",
    "print('Valid RMSE: ', valid_rmse)\n",
    "print('Training time taken: {:.2f}s'.format(train_time))\n",
    "print('Validation time taken: {:.2f}s'.format(valid_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6x1tj0zothu",
   "metadata": {},
   "source": [
    "### Prepare Data for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nn1r7mrp31p",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4D shape for CNN\n",
    "train_CSI_CNN = train_CSI_norm\n",
    "valid_CSI_CNN = valid_CSI_norm\n",
    "\n",
    "print('CNN shape:', train_CSI_CNN.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cnn_section",
   "metadata": {},
   "source": [
    "## Neural Network: CNN Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cnn_model",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 6,737,090\n"
     ]
    }
   ],
   "source": [
    "class CNNRegressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNRegressor, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 1 * 408, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutional block 1\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # Convolutional block 2\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # Flattening\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = CNNRegressor()\n",
    "\n",
    "# Count params\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total parameters: {total_params:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cnn_train",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 59.7920\n",
      "Epoch [2/10], Loss: 35.9650\n",
      "Epoch [3/10], Loss: 26.3386\n",
      "Epoch [4/10], Loss: 21.3001\n",
      "Epoch [5/10], Loss: 18.6085\n",
      "Epoch [6/10], Loss: 17.3501\n",
      "Epoch [7/10], Loss: 15.3680\n",
      "Epoch [8/10], Loss: 13.9490\n",
      "Epoch [9/10], Loss: 13.9110\n",
      "Epoch [10/10], Loss: 12.4909\n",
      "Training completed in 578.51 seconds\n"
     ]
    }
   ],
   "source": [
    "# Setup training\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_dataset = TensorDataset(train_CSI_CNN, train_label)\n",
    "valid_dataset = TensorDataset(valid_CSI_CNN, valid_label)\n",
    "\n",
    "# Dataloaders\n",
    "BS = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=BS, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BS, shuffle=False)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "\n",
    "train_time = time.time() - start_time\n",
    "print(f'Training completed in {train_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cnn_eval",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE: 14.2634\n",
      "Validation RMSE: 3.7767\n",
      "Testing time: 9.8696s\n"
     ]
    }
   ],
   "source": [
    "# Eval\n",
    "model.eval()\n",
    "start_time = time.time()\n",
    "\n",
    "valid_predictions = []\n",
    "valid_labels_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in valid_loader:\n",
    "        outputs = model(inputs)\n",
    "        valid_predictions.extend(outputs.tolist())\n",
    "        valid_labels_list.extend(labels.tolist())\n",
    "\n",
    "test_time = time.time() - start_time\n",
    "\n",
    "# Calculate metrics and performance\n",
    "valid_predictions = np.array(valid_predictions)\n",
    "valid_labels_list = np.array(valid_labels_list)\n",
    "\n",
    "mse = mean_squared_error(valid_labels_list, valid_predictions)\n",
    "rmse = math.sqrt(mse)\n",
    "\n",
    "print(f'Validation MSE: {mse:.4f}')\n",
    "print(f'Validation RMSE: {rmse:.4f}')\n",
    "print(f'Testing time: {test_time:.4f}s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
